---
title: "Statistical Analysis - Data Wrangling"
author: "Malte Lund"
format: html
editor: visual
---

## Loading packages - Setting options

```{r}
library(renv)
#renv::init()
#install.packages("readxl")
library("readxl")
library(dplyr)
library(here)
library(snakecase)
library(ggplot2)
library(stringr)
library(writexl)
#install.packages("targets")
#library(targets)
#use_targets()
set.seed(42069)

#set_here(path="C:/Users/mada0011/Desktop/Offline Statistics/Lupex-Statistics")
```

## Importing the data

```{r warning = F}

rawdata<-read_excel(path=here("Data/EasyTrialRawDataNoDateofBirth.xlsx"))
colnames(rawdata)<-to_snake_case(colnames(rawdata))
nanostring<-read_excel((path=here("data/NanoStringData/Kopi af BX0616 Raw data.xlsx")))
nanostring_norm<-read_excel((path=here("data/NanoStringData/Kopi af BX0616 Normalized data.xlsx")))
biox<-read_excel((path=here("data/NanoStringData/BioXpedia_BX0616_OnlyCols.xlsx")))

```

### Create modified data with mITT and PP from rawdata

```{r}
data<-rawdata%>%rowwise()%>%mutate(
  schema_name = case_when(
    is.na(schema_name) ~ "2g. Visit 2: SpÃ¸rgeskemaer",
    T~ schema_name
  ))%>%ungroup()%>%
  mutate(id = to_snake_case(allocation_no),
           mITT = case_when(
             allocation_no == "LUP003" ~ #Excluded due to pre-transplantation
               case_when(task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ 0, 
                         task_name == "Visit 2 - Baseline" ~ 0,
                         task_name == "Visit 3 - Acute Exercise Bout" ~ 0,
                         T~1),
             allocation_no == "LUP014" ~ #Excluded due to flare with increased SLEDAI above 10, baseline repreated at a later date.
               case_when(
                 task_name == "Visit 2 - Baseline" ~ 0,
                 T ~ 1),
             allocation_no == "LUP021" ~ 0, #Excluded due to pregnancy
             allocation_no == "LUP006" ~ 0, #Excluded due to SLEDAI = 14 at baseline
             allocation_no == "LUP001" ~ #Excluded due to insufficient test
               case_when(
               task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ 0,
               task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion_002" ~ 1,
               T ~ 1
             ),
             T ~ 1),
         PP = case_when( #TODO when we get the PP we need to add this variable.
             T ~ 0)
           )

```

## Choose mITT, PP or ITT (by leaving both F)

```{r}
mITT = T
PP = F
if (mITT){
  data<-data%>%filter(
    mITT == 1
  )
  
}

if (PP){
  data<-data%>%filter(
    PP == 1
  )
}

```

## Creating data as sets

```{r evaluate = F}

not_all_na <- function(x) any(!is.na(x))

aerobiccapacity.data <- rawdata %>% filter( schema_name=="2e. Visit 2: VO2max protokol") %>% select(where(not_all_na))%>%mutate(
  borg=`borg_skala_efter_test`+6,
  timepoint=case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline", #TODO finish this: This line is supposed to find the latest of the baseline variables and use that as the date. 
    T~NA_character_
  )
)%>%rename(id=allocation_no)



```

## Transposing the Nanostring Data

```{r}
Nanostring_Transpose <- as.data.frame(t(nanostring_norm[,c(-1,-2)]))
colnames(Nanostring_Transpose)<-nanostring_norm$`Probe Name`
Nanostring_Transpose$BX_ID<-rownames(Nanostring_Transpose)

library(tidyr)
#Getting the BioXpedia ID to our ID
biox$BX_ID<-biox$`BXP ID`
nanostring_biox <- merge(biox,Nanostring_Transpose)

nanostring_biox <- nanostring_biox %>% mutate(timepoint = case_when(
  startsWith(`Customer Sample ID`, 'LU0') ~ "Extra",
  endsWith(`Customer Sample ID`, 'a') ~ "Baseline",
  endsWith(`Customer Sample ID`, 'b') ~ "Followup",
  startsWith(`Customer Sample ID`, 'HC') ~ "HealthyControl",
  T~NA_character_
),
ID = case_when(
  startsWith(`Customer Sample ID`, 'LU0') ~ paste("LUP00",tidyr::extract_numeric(`Customer Sample ID`),sep=""),
  endsWith(`Customer Sample ID`, 'a') ~ substr(`Customer Sample ID`, start=1, stop=6),
  endsWith(`Customer Sample ID`, 'b') ~ substr(`Customer Sample ID`, start=1, stop=6),
  startsWith(`Customer Sample ID`, 'HC') ~ `Customer Sample ID`,
  T~NA_character_
))
```

## mRNA content normalization flag:

Note which genes have an mRNA content normalization flag,

from the QC report found in the documents section of this project: Comments for the QC properties of the Nanostring data The samples BX0616_014, BX0616_103, and BX0616_110 have an mRNA Content Normalization flag, indicating that the mRNA content in these samples was too low for the normalization method to function as intended. This means that the sample should be used with caution in statistical analysis, if not removed. No other QC flags were detected for the data. This means that the quality control and normalization of the samples are considered satisfying and within the range of the expected. Please contact us if further questions arise at XXX\@bioxpedia.com or YYY\@bioxpedia.com

```{r}
nanostring_biox <- nanostring_biox %>% mutate(
  mRNA.content.normalization.flag = case_when(
    BX_ID == "BX0616_014" ~ 1,
    BX_ID == "BX0616_103" ~ 1,
    BX_ID == "BX0616_110" ~ 1,
    T ~ 0
  )
)

nanostring_biox_complete_case <- nanostring_biox

nanostring_biox<-nanostring_biox%>%filter(
  mRNA.content.normalization.flag != 1
)
```

## Calculating Cytokine scores

```{r}
#These score sets are from the protocol chapter 3.9.9
cytokine_score_sets <- list(
  M1.2 = #According to Chiche et al.
    c("CXCL10", 
           "DDX60", 
           "EPSTI1", 
           "HERC5", 
           "IFI44", 
           "IFI44L", 
           "IFIT1", 
           "IFIT3", 
           "IFITM3", 
           "ISG15", 
           "LAMP3", 
           "LY6E", 
           "MX1", 
           "OAS1", 
           "OAS2", 
           "OAS3", 
           "OASL", 
           "RSAD2", 
           "RTP4", 
           "SERPING1"),
  M3.4 = c("DDX58",
           "GBP1",
           "GBP3",
           "GBP5",
           "HERC6",
           "IFI35",
           "IFIH1",
           "IFIT2",
           "IFIT5",
           "IFITM1",
           "LGALS3BP",
           "PARP9",
           "PLSCR1",
           "SOCS1",
           "STAT1",
           "STAT2",
           "ZBP1"),
  M5.12 = c("ADAR",
            "BST2",
            "GBP2",
            "IRF9",
            "ISG20",
            "SP100",
            "TRIM21",
            "TRIM25"),
  IFN1.EL.Sherb = #According to El-Sherbiny et al.
    c("ISG15",
      "IFI44",
      "IFI27",
      "CXCL10",
      "RSAD2",
      "IFIT1",
      "IFI44L",
      "CCL8",
      "XAF1",
      "IFI6",
      "GBP1",
      "IRF7",
      "CEACAM1"
      ),
  IFN2.EL.Sherb = #According to El-Sherbiny et al. 
    c("ISG15",
      "LAMP3",
      "IFIH1",
      "PHF11",
      "SERPING1",
      "IFI16",
      "BST2",
      "SP100",
      "NT5C3B",
      "SOCS1",
      "TRIM38",
      "UNC93B1",
      "UBE2L6",
      "STAT1",
      "TAP1"),
IFN2.Siddiqi = c("S100A9", 
                 "S100A8",
                 "FCGR1A"),
IL6 = c("A2M",
        "ADCY7",
        #"AER61", #NOT IN DATASET BUT WANTED BY PROTOCL (??),
        "Ar",
        "BRCA2",
        "PSTK",
        "ITGAL",
        "CD70",
        "CDK9",
        "CREB1",
        "FCRL2",
        "Foxq1",
        "GADD45B",
        "GRP1",
        "HSP90AB1",
        "IER3",
        "IRAK3",
        "JDP2",
        "LRG-1",
        #"LDB2", #NOT IN DATASET BUT WANTED BY PROTOCL (??),
        "CCL2", #Known as MCP-1 in protocol
        "MGP",
        "PLAUR",
        "RAG1",
        #"RAG2", #Downregulated unsure how to include across mean, unless multiplied by -1 (??)
        "RELA",
        "SOCS3",
        "VEGFA",
        "STAT3"),
TNF= c("ADAM17",
       "ARNT2",
       "CASP3",
       "CASP5",
       "CCR1",
       "CD22",
       "GJA3",
       "GPR35",
       "TAB3",
       "CCL2", #Known as MCP-1 in protocol
       #"PLAUR", #Downregulated
       "PPAP2A",
       "PPP1CA",
       "SPP1",
       "SYNGR3"
       )
)

#Means and SD of healthy controls
mean.healthy.controls <- nanostring_biox %>% filter(timepoint=="HealthyControl")%>% summarise_at(
  12:837,mean
)


sd.healthy.controls <- nanostring_biox %>% filter(timepoint=="HealthyControl")%>% summarise_at(
  12:837,sd
)

mean.sd.healthy.controls<-rbind(mean.healthy.controls, sd.healthy.controls)
rownames(mean.sd.healthy.controls)<-c("mean","sd")

#Calculate all Z-scores as noted in the protocol:

Z_scores_nano <- nanostring_biox

cols <- 12:837

#This nested for loops loops over each ID; and for each ID it goes to each gene count and corrects it to a z-score compared to healthy control (as described in the protocol section 3.9.9.1).

for (ID in 1:nrow(Z_scores_nano)){
for( gene in cols ){
  Z_scores_nano[ID,gene]<-
      (nanostring_biox[ID,gene]-mean.sd.healthy.controls[1,gene-11])/
                  mean.sd.healthy.controls[1,gene-11]
  
}}

#This is taking the average of a group of z-scores and puts it into the relevant modules as described in the protocol section 3.9.9.3

Cytokine_Panel_aggregates<-Z_scores_nano %>% mutate(
  M1.2 =  rowMeans(select(Z_scores_nano, 
                          cytokine_score_sets$M1.2)),
  M3.4 =  rowMeans(select(Z_scores_nano, 
                          cytokine_score_sets$M3.4)),
  M5.12 =  rowMeans(select(Z_scores_nano, 
                           cytokine_score_sets$M5.12)),
  IFN1.EL.Sherb =  rowMeans(select(Z_scores_nano,
                                   cytokine_score_sets$IFN1.EL.Sherb)),
  IFN2.EL.Sherb =  rowMeans(select(Z_scores_nano, 
                                   cytokine_score_sets$IFN2.EL.Sherb)),
  IFN2.Siddiqi =  rowMeans(select(Z_scores_nano,
                          cytokine_score_sets$IFN2.Siddiqi)),
  IL.6.related =  rowMeans(select(Z_scores_nano,
                          cytokine_score_sets$IL6)),
  TNF.related =  rowMeans(select(Z_scores_nano,
                          cytokine_score_sets$TNF))
  ) 

#Geometric Mean scores calculated as described in the protocol 3.9.9.2. This method uses a different tactic than the one described in the protocol, while the result is mathmatically the same, the protocol says to take the nth root of the product of n-genes in each panel, this method instead takes logarithm of each gene, averages those, and then takes the exponent. Which is mathematically equivalent. Here is a simply test to show that:
#test <- 1:10
#product(test)^(1/length(test))
#exp(mean(log(test)))
#The reason we use a different method is due to floating point error, the product of these can get quite large, and therefore when we take the nth root we would lose data due to rounding. So doing it the second way is less computationally intensive.

Cytokine_Panel_geomeans<-nanostring_biox %>% mutate(
  M1.2.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$M1.2)))),
  M3.4.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$M3.4)))),
  M1.2.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$M1.2)))),
  M5.12.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$M5.12)))),
  IFN1.EL.Sherb.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$IFN1.EL.Sherb)))),
  IFN2.EL.Sherb.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$IFN2.EL.Sherb)))),
  IFN2.Siddiqi.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$IFN2.Siddiqi)))),
  IL.6.related.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$IL6)))),
  TNF.related.Geomean = exp(rowMeans(log(select(nanostring_biox,
                          cytokine_score_sets$TNF)))))

cytokine_scores <- Cytokine_Panel_aggregates%>%
  select(ID,timepoint,
        M1.2,M3.4,M5.12, 
        IFN1.EL.Sherb,IFN2.EL.Sherb,
        IFN2.Siddiqi,
        IL.6.related,
        TNF.related)%>%merge(
          select(Cytokine_Panel_geomeans,
                 ID,timepoint,
        M1.2.Geomean,M3.4.Geomean,M5.12.Geomean, 
        IFN1.EL.Sherb.Geomean,IFN2.EL.Sherb.Geomean,
        IFN2.Siddiqi.Geomean,
        IL.6.related.Geomean,
        TNF.related.Geomean)
        )

cytokine_scores<-cytokine_scores%>%filter(!is.na(ID))
colnames(cytokine_scores)<-to_snake_case(colnames(cytokine_scores))
cytokine_scores$id<-to_snake_case(cytokine_scores$id)

write_xlsx(cytokine_scores, path=here("output","cytokinescores.xlsx")) #To load from later

write_xlsx(nanostring_biox, path=here("output","nanostring_ID_as_rows.xlsx"))

cytokine_baseline<-cytokine_scores%>%filter(timepoint=="Baseline")%>%dplyr::select(-timepoint)
```

## Merge cytokinescores at baseline and randomization information

```{r}
group<-read_excel(path=here("data","RandomizationKey_pingvin_sÃ¸lÃ¸ve.xlsx"))%>%select(ID,Allocation)%>%
  rename(treatment=Allocation)
colnames(group)<-to_snake_case(colnames(group))
group$id<-to_snake_case(group$id)



#cytokine_baseline$id<-to_snake_case(cytokine_baseline$id)
group_cytokine<-merge(group,
                      cytokine_baseline, all=T)

write_xlsx(group_cytokine, path = here("Data","grouping_cytokine.xlsx"))

```

### Merge group and cytokine data with other datasets

```{r}


#install.packages("stringr")
require(stringr)

data$schema_name<-data$schema_name%>%snakecase::to_snake_case()%>%str_replace_all("[:digit:]", "")
schema_names<-unique(data$schema_name)




```

## Write all data to sets

```{r}

#It is a bit easier to select data frames that are not empty in a for loop. The data taken directly from easy-trial is, frankly, a huge mess, to sort it, we divide the data into subset based on the schemas they were collected on. 

not_all_na <- function(x) any(!is.na(x))

for (schema in schema_names){
  nam<-paste(as.character(schema),ifelse(PP,".PP",""),ifelse(mITT,".mITT",""),".data", sep="") 
  
  df<-data %>% 
    filter( schema_name==schema) %>% 
    select(where(not_all_na))%>%
    left_join(y=group_cytokine, join_by(id))

  write_xlsx(df,path=paste(here("Data/easy_trial_seperate_schemes/",paste(nam,".xlsx"))))
  assign(nam, df)
}



```

## Create Vo2Max data set

First created in the vo2maxdata.qmd file, but I wanted it here for completion with the table, I can load the data in the other file instead.

```{r}
vo2max.data <- read_excel(path=
                            here(paste0("Data/easy_trial_seperate_schemes/_e_visit__vo__max_protokol.",
                                        ifelse(mITT,"mITT",
                                               ifelse(PP,"PP","")),
                                        ".data .xlsx")))%>%
  mutate(
  borg=`borg_skala_efter_test`+6,
  timepoint=
  case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline", #TODO finish this: This line is supposed to find the latest of the baseline variables and use that as the date. 
    T~NA_character_
  )
)%>%filter(!is.na(timepoint))%>%
#Constrain Baseline
mutate(
  treat = case_when(
    timepoint == "baseline" ~ "Pingvin",
    timepoint == "screening" ~ "Pingvin",
    timepoint == "followup" ~ treatment,
    T~NA_character_
  ))%>%mutate(
    treat = factor(treat, levels = c("Pingvin", "SÃ¸lÃ¸ve")),
    timepoint = factor(timepoint, levels = c("screening", "baseline", "followup"))
  )

#write it to a file to be accessed again by the script assessing models for VO2max
write_xlsx(x=vo2max.data, 
           path = here("Data",paste0("vo2max", ifelse(mITT, "_mITT", ifelse(PP,"_PP","")),".xlsx")))
```

## Create questionnaires set

First created in the other .qmd file, but I wanted it here so I could use it when collecting the combined data set for table 1.

```{r}

questionnaires <- read_xlsx(path=here("Data/easy_trial_seperate_schemes/_g_visit__spÃ¸rgeskemaer.mITT.data .xlsx"))%>%mutate(
  timepoint=
  case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline",  
    T~NA_character_
  )
)%>%filter(!is.na(timepoint))%>%mutate(
  id = to_snake_case(allocation_no),
  treat = case_when(
    timepoint == "baseline" ~ "Pingvin",
    timepoint == "screening" ~ "Pingvin",
    timepoint == "followup" ~ treatment,
    T~NA_character_
  ))%>%mutate(
    treat = factor(treat, levels = c("Pingvin", "SÃ¸lÃ¸ve")),
    timepoint = factor(timepoint, levels = c("screening", "baseline", "followup"))
  )%>%filter(!is.na(schema_version))

questionnaires <- questionnaires[,colSums(is.na(questionnaires))<nrow(questionnaires)]%>%mutate()
str(questionnaires)

questionnaires$fss_laengerevarende_aktivitet<-as.numeric(questionnaires$fss_laengerevarende_aktivitet)   
questionnaires$fss_funktionsindkraenkning <-as.numeric(questionnaires$fss_funktionsindkraenkning )
questionnaires$slaq_unusual_headache<- as.numeric(questionnaires$slaq_unusual_headache)
questionnaires$slaq_muskelsvaghed <- as.numeric(questionnaires$slaq_muskelsvaghed)
questionnaires$sf_36_7[56] <- 3 #TODO check this value, it is written as both 2 and 4 in the database, so I take the average.
questionnaires$sf_36_7<-as.numeric(questionnaires$sf_36_7)
questionnaires$sf_36_8<-as.numeric(questionnaires$sf_36_8)

```

### Compute FSS composite scores:

```{r}
questionnaires.data <- questionnaires %>% mutate(
  fatigue.mean = rowMeans(select(questionnaires, c(
    "fss_motivation",
    "fss_motion",
    "fss_let_traet",
    "fss_begraens",
    "fss_problemer",
    "fss_laengerevarende_aktivitet",
    "fss_pligter_og_ansvar",
    "fss_funktionsindkraenkning",
    "fss_arbejde_familie_fritid")),
    na.rm=T))%>%filter(!is.na(fatigue.mean))
```

### Create SF-36 composites

Code taken from my own code in RABEX using this guide:

https://www.rand.org/health-care/surveys_tools/mos/36-item-short-form/scoring.html https://github.com/dgrisafe/R-SF-36/blob/master/SF-36%20Scoring.Rmd

```{r}
SF_36<-questionnaires.data %>% select(id,timepoint, treatment,52:87)

colnames(SF_36)[4:39] <- str_replace(string=colnames(SF_36)[4:39], pattern = "_36_", replacement = "_")
SF_36[4:39]<-sapply(SF_36[4:39],as.numeric)

SF_36_recoded<-SF_36%>% #Weighing columns according to https://www.rand.org/health-care/surveys_tools/mos/36-item-short-form/scoring.html
  mutate(across( # 5 Point reverse
                .cols=c(sf_1, #1 pÃ¥ RAND
                        sf_2, #2 pÃ¥ RAND
                        sf_6, #20 pÃ¥ RAND
                        sf_8, #22 pÃ¥ RAND
                        sf_11_b,
                        sf_11_d
                        ),~100-(.-1)*25)) %>%
  mutate(across( # 3 Point no reverse
                .cols=c(sf_3_a,
                        sf_3_b,
                        sf_3_c,
                        sf_3_d,
                        sf_3_e,
                        sf_3_f,
                        sf_3_g,
                        sf_3_h,
                        sf_3_i,
                        sf_3_j),~(.-1)*50))%>%
  mutate(across( # 2 Point no reverse
                .cols=c(sf_4_a,
                        sf_4_b,
                        sf_4_c,
                        sf_4_d,
                        sf_5_a,
                        sf_5_b,
                        sf_5_c),~(.-1)*100))%>%
  mutate(across( # 6 Point reverse
                .cols=c(sf_7,   #21 pÃ¥ RAND
                        sf_9_a, #23 pÃ¥ RAND
                        sf_9_d, #26 pÃ¥ RAND
                        sf_9_e, #27 pÃ¥ RAND
                        sf_9_h) #30 pÃ¥ RAND
                  ,~100-(.-1)*100/5))%>%
  mutate(across( # 6 Point no reverse
                .cols=c(sf_9_b, #24 pÃ¥ RAND
                        sf_9_c, #25 pÃ¥ RAND
                        sf_9_f, #28 pÃ¥ RAND
                        sf_9_g, #29 pÃ¥ RAND
                        sf_9_i  #31 pÃ¥ RAND
                        ) 
                  ,~(.-1)*100/5))%>%
  mutate(across( # 5 Point no reverse
                .cols=c(sf_10, #32 pÃ¥ RAND
                        sf_11_a, #33 pÃ¥ RAND
                        sf_11_c #35 pÃ¥ RAND
                        ) 
                  ,~(.-1)*100/4))

#Establish Domains
SF_36_recoded <-SF_36_recoded %>% group_by(id,timepoint)%>%mutate(
  physical_function = mean(c(             sf_3_a,
                                          sf_3_b,
                                          sf_3_c,
                                          sf_3_d,
                                          sf_3_e,
                                          sf_3_f,
                                          sf_3_g,
                                          sf_3_h,
                                          sf_3_i,
                                          sf_3_j),na.rm=T),
  role_limitations_physical_health = mean(c(
                                          sf_4_a,
                                          sf_4_b,
                                          sf_4_c,
                                          sf_4_d), na.rm=T),
  role_limitations_emotional_health = mean(c(
                                          sf_5_a,
                                          sf_5_b,
                                          sf_5_c), na.rm=T),
  energy_fatigue = mean(c(
                                          sf_9_a, #23 pÃ¥ RAND
                                          sf_9_e, #27 pÃ¥ RAND
                                          sf_9_g, #29 pÃ¥ RAND
                                          sf_9_i  #31 pÃ¥ RAND
                        ), na.rm=T),
  emotional_well_being = mean(c(
                                          sf_9_b, #24 pÃ¥ RAND
                                          sf_9_c, #25 pÃ¥ RAND
                                          sf_9_d, #26 pÃ¥ RAND
                                          sf_9_f, #28 pÃ¥ RAND
                                          sf_9_h) #30 pÃ¥ RAND
                        ,na.rm=T),
  social_functioning = mean(c(
                                          sf_6, #20 pÃ¥ RAND
                                          sf_10 #32 pÃ¥ RAND
                        ),na.rm=T),
  pain = mean(c(
                                          sf_7, #21 pÃ¥ RAND
                                          sf_8  #22 pÃ¥ RAND
                        ),na.rm=T),
  general_health = mean(c(
                                          sf_1,     #01 pÃ¥ RAND
                                          sf_11_a,  #33 pÃ¥ RAND
                                          sf_11_b,  #34 pÃ¥ RAND
                                          sf_11_c,  #35 pÃ¥ RAND
                                          sf_11_d   #36 pÃ¥ RAND
                        ),na.rm=T)
)%>%
  relocate(id,timepoint,physical_function,role_limitations_physical_health,role_limitations_emotional_health,energy_fatigue,emotional_well_being,social_functioning,pain,general_health)



```

### SF-36 conversion to aggregate scores

We'll be using this guide:

https://www.researchgate.net/profile/John-Ware-6/publication/292390260_SF-36_Physical_and_Mental_Health_Summary_Scales_a_User%27s_Manual/links/5af580264585157136caee31/SF-36-Physical-and-Mental-Health-Summary-Scales-a-Users-Manual.pdf

```{r}
SF36USMeansSD<-read_excel(here("Input/SF36USPOPMEANSD.xlsx"))
rownames(SF36USMeansSD)<-SF36USMeansSD$...1

#SF36USMeansSD$Mean

SF.36.Zscores <- SF_36_recoded%>%select(id,timepoint,
                      physical_function,
                      role_limitations_physical_health,
                      role_limitations_emotional_health,
                      energy_fatigue,
                      emotional_well_being,
                      social_functioning,
                      pain,
                      general_health)%>%mutate(
                        z_PF = (physical_function - SF36USMeansSD$Mean[1]) / SF36USMeansSD$SD[1],
                        z_RP = (role_limitations_physical_health - SF36USMeansSD$Mean[2]) / SF36USMeansSD$SD[2],
                        z_BP = (pain - SF36USMeansSD$Mean[3]) / SF36USMeansSD$SD[3],
                        z_GH = (general_health - SF36USMeansSD$Mean[4]) / SF36USMeansSD$SD[4],
                        z_VT = (energy_fatigue - SF36USMeansSD$Mean[5]) / SF36USMeansSD$SD[5],
                        z_SF = (social_functioning - SF36USMeansSD$Mean[6]) / SF36USMeansSD$SD[6],
                        z_RE = (role_limitations_emotional_health - SF36USMeansSD$Mean[7]) / SF36USMeansSD$SD[7],
                        z_MH = (emotional_well_being - SF36USMeansSD$Mean[8]) / SF36USMeansSD$SD[8],
                        
                      )%>%mutate(
                        aggregated.physical.score = 
                          z_PF * 0.42402 + 
                          z_RP * 0.35119 + 
                          z_BP * 0.31754 + 
                          z_GH * 0.24954 + 
                          z_VT * 0.02877 + 
                          z_SF * -0.00753 +
                          z_RE * -0.19206 +
                          z_MH * -0.22069,
                        aggregated.mental.score = 
                          z_PF * -0.22999 + 
                          z_RP * -0.12329 + 
                          z_BP * -0.09731 + 
                          z_GH * -0.01571 + 
                          z_VT * 0.23534 + 
                          z_SF * 0.25876 +
                          z_RE * 0.43407 +
                          z_MH * 0.48581 
                      )%>%mutate(
                        physical.component.score = 50 + aggregated.physical.score*10,
                        mental.component.score = 50 + aggregated.mental.score*10
                      )


SF_36_recoded<-SF.36.Zscores %>% select(id,timepoint,physical.component.score,mental.component.score) %>% merge(SF_36_recoded)

SF_36_aggregates <- SF_36_recoded %>% select(id, timepoint, 
                                             physical.component.score, mental.component.score,
                                             physical_function, role_limitations_physical_health,
                                             role_limitations_emotional_health, energy_fatigue,
                                             emotional_well_being,
                                             social_functioning,
                                             pain,
                                             general_health)

questionnaires.data.SF_36<-left_join(questionnaires.data,SF_36_aggregates,by=c("id","timepoint"))%>%
  relocate(id, timepoint, treatment,
           fatigue.mean,
           m_1_2,
           physical.component.score, mental.component.score,
           physical_function, role_limitations_physical_health, role_limitations_emotional_health, energy_fatigue, emotional_well_being, social_functioning, pain, general_health)

```

### Q-Slaq

We are using the method suggested by Svennungson et al. from this paper: https://lupus.bmj.com/content/8/1/e000471.long

```{r}
questionnaires.combined.data<-questionnaires.data.SF_36%>%mutate(
  qslaq_score = 
    vÃ¦gttab_uden_du_har_forsÃ¸gt_det +
    case_when(is.na(slaq_traethed)~0,
              T ~ slaq_traethed) + 
    slaq_feber +
    slaq_glandler +
    case_when(
      slaq_udslaet_kinder >=1 ~ 1,
      slaq_sol_udslaet >= 1 ~ 1,
      slaq_mund_naese_saar >= 1 ~ 1,
      T ~ 0
    ) +
    slaq_alopeci +
    case_when(
      slaq_dyspnoe >= slaq_resp_smerter ~ slaq_dyspnoe,
      T~slaq_resp_smerter) +
    slaq_mavesmerter +
    case_when(slaq_glemsomhed  >=  slaq_depression ~ slaq_glemsomhed, 
              T ~ slaq_depression) +
    slaq_unusual_headache +
    case_when(
      slaq_muskelsvaghed == 0 ~ slaq_myalgi,
      T~slaq_muskelsvaghed) + 
    case_when(
      slaq_swollen_joints == 0 ~ slaq_smerter_stivhed_led,
      T~slaq_swollen_joints),
  qslaq_symptom_score =
    #TODO put in symptom score
    case_when(is.na(vÃ¦gttab_uden_du_har_forsÃ¸gt_det) ~
                    case_when(is.na(slaq_traethed) ~
                            case_when(is.na(slaq_feber) ~
                                        NA_real_, 
                                      T~0),
                        T~0),
                  T~0)+
    case_when(vÃ¦gttab_uden_du_har_forsÃ¸gt_det>= 1 ~ 1,
              T~0)+
    case_when(slaq_traethed>= 1 ~ 1,
              T~0)+
    case_when(slaq_feber>= 1 ~ 1,
              T~0)+
    case_when(slaq_glandler>= 1 ~ 1,
              T~0)+
    case_when(slaq_udslaet_kinder>= 1 ~ 1,
              T~0)+
    case_when(slaq_sol_udslaet>= 1 ~ 1,
              T~0)+
    case_when(slaq_mund_naese_saar>= 1 ~ 1,
              T~0)+
    case_when(slaq_alopeci>= 1 ~ 1,
              T~0)+
    case_when(slaq_dyspnoe>= 1 ~ 1,
              T~0)+
    case_when(slaq_resp_smerter>= 1 ~ 1,
              T~0)+
    case_when(slaq_mavesmerter>= 1 ~ 1,
              T~0)+
    case_when(slaq_glemsomhed>= 1 ~ 1,
              T~0)+
    case_when(slaq_depression>= 1 ~ 1,
              T~0)+
    case_when(slaq_unusual_headache>= 1 ~ 1,
              T~0)+
    case_when(slaq_muskelsvaghed>= 1 ~ 1,
              T~0)+
    case_when(slaq_myalgi>= 1 ~ 1,
              T~0)+
    case_when(slaq_swollen_joints>= 1 ~ 1,
              T~0)+
    case_when(slaq_smerter_stivhed_led>= 1 ~ 1,
              T~0))
```

### Save questionnaires data

```{r}
questionnaires.combined.data%>%write_xlsx(path = here("Output",paste0(
                       "Questionnaires_combined",
                       ifelse(mITT,"_mITT",""),ifelse(PP,"_PP",""),
                       ".xlsx")))
```

# SLICC Criteria

```{r}
SLICC.data <- anamnese_og_objektiv_undersÃ¸gelse_baseline_followup.mITT.data %>% dplyr::select(id, baseline_eller_followup, task_name,
    slicc_feber, slicc_mucokutan, slicc_artrit, slicc_neurology, slicc_serositis, slicc_hematology, slicc_nefrologisk,
    slicc_antiphospholipids,  slicc_complement, slicc_sle_specific_antibodies)%>%filter(
      baseline_eller_followup == 0
      )%>%mutate(slicc_score = 
    ###Clinical Domain:
      slicc_feber * 2 +
       
      case_when(
        str_detect(slicc_mucokutan, "4") ~ 6,
        str_detect(slicc_mucokutan, "3") ~ 4,
        str_detect(slicc_mucokutan, "2") ~ 2,
        str_detect(slicc_mucokutan, "1") ~ 2,
        str_detect(slicc_mucokutan, "0") ~ 0,
        T~ NA_real_) +
        
      case_when(
        str_detect(slicc_artrit, "2") ~ 6,
        str_detect(slicc_artrit, "1") ~ 6,
        str_detect(slicc_artrit, "0") ~ 0,
        T~ NA_real_) +
        
      case_when(
        str_detect(slicc_neurology, "3") ~ 5,
        str_detect(slicc_neurology, "2") ~ 3,
        str_detect(slicc_neurology, "1") ~ 2,
        str_detect(slicc_neurology, "0") ~ 0,
        T~ NA_real_) +
        
      case_when(
        str_detect(slicc_serositis, "2") ~ 6,
        str_detect(slicc_serositis, "1") ~ 5,
        str_detect(slicc_serositis, "0") ~ 0,
      T~ NA_real_) +
      
      case_when(
        str_detect(slicc_hematology, "4") ~ 4,
        str_detect(slicc_hematology, "3") ~ 3,
        str_detect(slicc_hematology, "0") ~ 0,
      T~ NA_real_) +
        
      case_when(
        str_detect(slicc_nefrologisk, "10") ~ 10,
        str_detect(slicc_nefrologisk, "8") ~ 8,
        str_detect(slicc_nefrologisk, "4") ~ 4,
        str_detect(slicc_nefrologisk, "0") ~ 0,
      T~ NA_real_) +
      
    ###Immunologic Domain:
      case_when(
        str_detect(slicc_antiphospholipids, "2") ~ 2,
        str_detect(slicc_antiphospholipids, "0") ~ 0,
      T~ NA_real_) +
      
      case_when(
        str_detect(slicc_complement, "4") ~ 4,
        str_detect(slicc_complement, "3") ~ 3,
        str_detect(slicc_complement, "0") ~ 0,
      T~ NA_real_) +
      
      case_when(
        str_detect(slicc_sle_specific_antibodies, "6") ~ 6,
        str_detect(slicc_sle_specific_antibodies, "0") ~ 0,
      T~ NA_real_)
    )

#Save SLICC data

write_xlsx(SLICC.data,
           path = here("Output", paste0(
                       "SLICC_data",
                       ifelse(mITT,"_mITT",""),ifelse(PP,"_PP",""),
                       ".xlsx")))
```

# SLEDAI

```{r}
SLEDAI.data <- `_j_selena_sledai_score_sri_.mITT.data` %>% dplyr::select(
  id, treatment, task_name,
  vas_sledai_physician, 
  kramper_sledai:sledai_leukopeni
  ) %>% mutate(
  timepoint = case_when(
    str_detect(task_name, "Baseline") ~ "baseline",
    str_detect(task_name, "Follow") ~ "followup",
    T~NA_character_
  ),
  .keep="unused")%>% 
    mutate(
    SLEDAI_score = 
      kramper_sledai +
      psykose_sledai +
      organisk_hjernepaavirkning_sledai+
      synforstyrrelser_sledai+
      kranienerve_sledai+
      lupus_hovedpine_sledai+
      cva_sledai+
      vaskulit_sledai+
      case_when(str_detect(artrit_sledai,"4")~4,
                T~0)+
      case_when(str_detect(myosit_sledai,"4")~4,
                T~0)+
      sledai_haematuri+
      case_when(str_detect(sledai_proteinuri,"4")~4,
                T~0)+
      sledai_pyuri+
      sledai_udslaet+
      sledai_haartab+
      sledai_slimhindesÃ¥r+
      sledai_pleurisy+
      sledai_perikardit+
      case_when(str_detect(sledai_complement,"2")~2,
                T~0)+
      sledai_ds_dna+
      sledai_feber+
      sledai_thrombopeni+
      sledai_leukopeni,
    SRI_50_score = NA_real_) %>% 
    relocate(
    id, treatment, timepoint, SLEDAI_score, SRI_50_score)

#write it to a file to be accessed again by the script assessing models for VO2max
write_xlsx(x=SLEDAI.data, 
           path = here("Data",paste0("SLEDAI.data", ifelse(mITT, "_mITT", ifelse(PP,"_PP","")),".xlsx")))

```

# Blood Samples

```{r}
library(lubridate)

#Date for baseline blood samples can be accessed from the OGTT data which has the date of when the blood samples were taken.
temp <- `_f_visit__oral_glucose_tolerance_test_ogtt_baseline.mITT.data` %>% dplyr::select(id, dato_ogtt,task_name)

Bloodsamples.data <- `_i_visit__blodprÃ¸ver_og_urinstix_baseline.mITT.data` %>% 
  #separate(
  #  col = task_start,
  #  into = c( "date" , "time"),
  #  sep = " "
  #)%>% ### THIS CODE IS DEPRECATED - At first I tried to find the dates on task_start, but the operator might have accessed some part of the task earlier or later, so Instead I find the dates input into the system.
  left_join(temp, 
                                                     by = c("id","task_name"))%>%rename(
                                                       
                                                       date = dato_ogtt
)%>%
  mutate(
    date = ymd(date),
    timepoint=case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline",
    T~NA_character_
  )
  ) 


Acute_exercise.data <- `_b_visit__acute_exercise_bout_og__x_.mITT.data` %>% 
  #dplyr::select(
  #id, treatment, sex, 
  #task_name, task_start, dato_acute_exercise_bout)%>%
  #mutate 
  #)%>%
  mutate(
    date = ymd(dato_acute_exercise_bout),
    timepoint=case_when(
    task_name == "Visit 3 - Acute Exercise Bout" ~ "baseline - acute bout",
    task_name == "Visit 3 - Acute Exercise Bout_002" ~ "baseline - acute bout",
    task_name == "Visit 6 - Acute Exercise Bout" ~ "followup - acute bout",
    T~NA_character_
  )
  )

Acute_exercise.metadata <- Acute_exercise.data %>% dplyr::select(
  id, date, timepoint)

Bloodsamples.metadata<-Bloodsamples.data %>% dplyr::select(
  id, date, timepoint
)

Bloodsamples.values <- read_excel(path=here("Data", 
                                            "Blood Samples",
                                            "All Data 2024-07-05.xlsx"))

colnames(Bloodsamples.values)<- to_snake_case(colnames(Bloodsamples.values))

Bloodsamples.values<-Bloodsamples.values %>% mutate(
  date = ymd(date),
  id = to_snake_case(id),
  tidspunkt = time,
  time = lubridate::hms(time)
)



Bloodsamples.combined.data <- 
  Bloodsamples.values %>% 
  left_join(Bloodsamples.metadata, by = c("id","date"))%>%
  left_join(Acute_exercise.metadata, by = c("id","date"))%>% mutate(
    timepoint = case_when(
      is.na(timepoint.y) ~ timepoint.x,
      is.na(timepoint.x) ~ timepoint.y,
      T ~ timepoint.x
    ),
    .keep = "unused"
  )
   
#To check the data I'm about to throw out, I run this:
Bloodsamples.combined.data.NA.timepoint <- Bloodsamples.combined.data%>%filter(
  is.na(timepoint)
)#%>%distinct(date, .keep_all = T)
View(Bloodsamples.combined.data.NA.timepoint)

#Seems reasonable, this data is not related to the study, but came into the blood-samples dataset from patient visits that were close to my dates. It's great to know that I can find PET-CT dates from this dataset. Also ID = Lup006 who I had to exclude because her blood samples showed her to have a SLEDAI > 10 post randomization.

Bloodsamples.combined.data <- 
  Bloodsamples.combined.data%>%filter(!is.na(timepoint))


library(hms)

Bloodsamples.combined.data2<-
  Bloodsamples.combined.data %>% 
  group_by(id, timepoint)%>%
  mutate(order_within_day = dense_rank(time))%>%
  ungroup()%>%
  arrange(time)%>%
  group_by(id, timepoint)%>%
  mutate(
  time_from_t0 = as.difftime(lubridate::hms(time) - lubridate::hms(time[1]),units="mins")/60
) %>%ungroup()%>%arrange(id,timepoint,date,time, tidspunkt)


#write it to a file to be accessed again by the script assessing models for Blood Samples
write_xlsx(x=Bloodsamples.combined.data2, 
           path = here("Data",paste0("Bloodsamples.data", ifelse(mITT, "_mITT", ifelse(PP,"_PP","")),".xlsx")))
  


Bloodsample.wide <- Bloodsamples.combined.data2%>%pivot_wider(
  id_cols=c(id, timepoint, date, tidspunkt, time, time_from_t0, order_within_day),
  names_from = var,
  values_from = value
)

#TODO put the average of multiple values in each cell in.
#We probably need a nested for loop iterating over all the cells in the frame to do this

#
```

##Slow code for extracting the wide format of Bloodsample.wide

Below is an incredibly slow way of taking the averages of the numeric cells, which does work, on my system it takes 1.2 minutes. I'll save it to an excel file, and only re-run it when it is needed.

```{r eval = F}
start_time <- Sys.time()
Bloodsample.wide2 <- Bloodsample.wide %>% dplyr::select(1:7)

cols<-8:ncol(Bloodsample.wide)

for(bloodsample in 8:ncol(Bloodsample.wide)){
  for (row in 1:nrow(Bloodsample.wide)) {
Bloodsample.wide2[row, bloodsample] <- 
  case_when(
      is.null(
      unlist(Bloodsample.wide[row, bloodsample])) ~ NA_real_,
      T~mean(as.numeric(unlist(Bloodsample.wide[row, bloodsample]))))
 }
}
colnames(Bloodsample.wide2)<-colnames(Bloodsample.wide)

write_xlsx(x=Bloodsample.wide2, 
           path = here("Data",
                       paste0("Bloodsamples.data.wide", 
                              ifelse(mITT, "_mITT", ifelse(PP,"_PP","")),
                              ".xlsx")))
end_time <- Sys.time()
end_time - start_time
rm(start_time, end_time)
```

```{r}
Bloodsamples<-read_excel(path = here("Data",
                       paste0("Bloodsamples.data.wide", 
                              ifelse(mITT, "_mITT", ifelse(PP,"_PP","")),
                              ".xlsx"))) #Okay so this doesn't work because it was nested vectors. Sigh. I have to take the average of each element.
#Bloodsample.wide%>%ggplot(aes(y=as.numeric(`Glukose;P`), x = as.numeric(time_from_t0)))+geom_point()
  #mutate(is_OGTT = case_when(n() > 1  & var %in% c("Glukose;P",
   #                                                  "Insulin;P",
    #                                                 "Proinsulin C-peptid;P") ~ TRUE,
     #                          TRUE ~ FALSE)) 
```

# AX3 Activity Measures

```{r}
library(readr)
AX3_Post_Back_PersonSummary <- 
  read_csv(here("Output",
                "AX3",
                "Post Back",
                "output_Post Back",
                "results",
                "part5_personsummary_WW_L40M100V400_T5A5.csv"))%>%mutate(
                  timepoint = "followup",
                  location = "back"
                )

AX3_Post_Thigh_PersonSummary <- 
  read_csv(here("Output",
                "AX3",
                "Post Thigh",
                "output_Post Thigh",
                "results",
                "part5_personsummary_WW_L40M100V400_T5A5.csv"))%>%mutate(
                  timepoint = "followup",
                  location = "thigh"
                )

AX3_Pre_Back_PersonSummary <- 
  read_csv(here("Output",
                "AX3",
                "Pre Back",
                "output_Pre Back",
                "results",
                "part5_personsummary_WW_L40M100V400_T5A5.csv"))%>%mutate(
                  timepoint = "baseline",
                  location = "back"
                )

AX3_Pre_Thigh_PersonSummary <- 
  read_csv(here("Output",
                "AX3",
                "Pre Thigh",
                "output_Pre Thigh",
                "results",
                "part5_personsummary_WW_L40M100V400_T5A5.csv"))%>%mutate(
                  timepoint = "baseline",
                  location = "thigh"
                )

AX3_Data.Frame<-bind_rows(AX3_Pre_Thigh_PersonSummary, 
                          AX3_Pre_Back_PersonSummary, 
                          AX3_Post_Thigh_PersonSummary,
                          AX3_Post_Back_PersonSummary)%>%mutate(
                            duration_daily_MVPA_pla = dur_day_total_MOD_min_pla + dur_day_total_VIG_min_pla,
                            id = to_snake_case(ID)
                          )%>%relocate(id, timepoint, location, 
                                       calendar_date, startday,
                                       dur_spt_min_pla,
                                       dur_day_total_IN_min_pla, dur_day_total_LIG_min_pla, duration_daily_MVPA_pla, dur_day_total_MOD_min_pla, dur_day_total_VIG_min_pla)
View(AX3_Data.Frame)
```

# Consort flowchart Generated using consort package

https://cran.r-project.org/web/packages/consort/vignettes/consort_diagram.html

```{r}
#install.packages("consort")
library(consort)
ListContacted<-read_excel(path=here("Data/ContactedList.xlsx"))%>%
  mutate(id=to_snake_case(Allocation_ID))%>%
  left_join(group)
#TODO add that one was excluded due to SLEDAI > 10

#consorttestdata<-data(dispos.data)

data.consort<-data.frame(
  trialno = ListContacted$Screeningnr,
  induction = ListContacted$id,
  exclusion = ListContacted$`Reason for decline`,
  arm = ListContacted$treatment,
  sbujid_dosed = ListContacted$sbujid_dosed,
  subjid_notdosed = ListContacted$subjid_notdosed,
  followup = ListContacted$followup,
  lost_followup = ListContacted$lost_followup,
  assessed = ListContacted$followup,
  no_value = ListContacted$lost_followup,
  mitt = ListContacted$sbujid_dosed
)


g <- consort_plot(data = data.consort,
                  orders = c(trialno = "SLE Patients contacted",
                             exclusion    = "Excluded/Could not participate",
                             induction   = "Baseline Measurements",
                             
                             arm     = "Randomized",
                             subjid_notdosed = "Did not begin intervention",
                             mitt = "Included in the mITT",
                             lost_followup = "Did not complete intervention",
                             followup = "Completed Followup"
                             ),
                  side_box = c("exclusion", 
                               "subjid_notdosed",
                               "lost_followup"),
                  allocation = "arm",
                  labels = c("1" = "Assessed in Outpatient Clinic", 
                             "2" = "Screening and Baseline Assessments",
                             "3" = "Randomization", 
                             "5" = "End of study"),
                  cex = 0.6) 
#install.packages("DiagrammeR")
#library(DiagrammeR)
plot(g)
g

ggplot2::ggsave(filename = here("output/graphics/consort_diagram.jpg"), 
                plot   = build_grid(g), 
                width  = 180, 
                height = 180,
                units = "mm",
                dpi = 300)
 
```

##Descriptive Graphics

```{r}


#https://stackoverflow.com/questions/16588022/how-can-i-reorder-the-x-axis-in-a-plot-in-r
#TODO make waterfall plot of Cytokine_scores
```

# TABLE 1 : Creating tables for table 1

## Creating Data sets

```{r}
#TODO create this dataset with all the variables needed in the SAP
table1.questionnaires <- questionnaires.combined.data %>% dplyr::select(
  id, sex, timepoint, 
  #m_1_2, ifn_1_el_sherb, m_3_4, ifn_2_el_sherb, m_5_12, 
  fatigue.mean, visuel_analog_trÃ¦thedsskala_vats_mÃ¥lt_i_mm,
  physical.component.score, mental.component.score, 
  sla_qvas, qslaq_score, qslaq_symptom_score)%>%dplyr::mutate(
    vas_fatigue = `visuel_analog_trÃ¦thedsskala_vats_mÃ¥lt_i_mm`,
    sf36_physical.component.score = physical.component.score,
    sf36_mental.component.score = mental.component.score,
    .keep = "unused"
  )%>%mutate(
  timepoint = factor(to_snake_case(as.character(timepoint)))
)

table1.cytokine_scores <- cytokine_scores%>%
  filter(timepoint != "HealthyControl")%>%
  filter(timepoint != "Extra")%>%
  filter(!is.na(timepoint))%>%mutate(
  timepoint = factor(to_snake_case(as.character(timepoint)))
)

table1.IFN.Quant.At.Baseline <- table1.cytokine_scores %>% 
  filter( timepoint =="baseline") %>%
  mutate(  id=id,
          m_1_2_quantile_at_baseline = 
           factor(findInterval(m_1_2, 
           c(-Inf, quantile(m_1_2, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         m_3_4_quantile_at_baseline = 
           factor(findInterval(m_3_4, 
           c(-Inf, quantile(m_3_4, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         m_5_12_quantile_at_baseline = 
           factor(findInterval(m_5_12, 
           c(-Inf, quantile(m_5_12, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         ifn1_el_sherb_quantile_at_baseline = 
           factor(findInterval(ifn_1_el_sherb, 
           c(-Inf, quantile(ifn_1_el_sherb, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         ifn2_el_sherb_quantile_at_baseline = 
           factor(findInterval(ifn_2_el_sherb, 
           c(-Inf, quantile(ifn_2_el_sherb, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         ifn2_siddiqi_quantile_at_baseline = 
           factor(findInterval(ifn_2_siddiqi, 
           c(-Inf, quantile(ifn_2_siddiqi, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         il_6_related_quantile_at_baseline = 
           factor(findInterval(il_6_related, 
           c(-Inf, quantile(il_6_related, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         tnf_related_quantile_at_baseline = 
           factor(findInterval(tnf_related, 
           c(-Inf, quantile(tnf_related, probs=c(0.33, .67)), Inf)),
           labels=c("lowest 33%","33-67%","highest 33%")),
         m_1_2_elevated = 
            factor(findInterval(m_1_2, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(m_1_2>2)%>%
                      pull(m_1_2)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         m_3_4_elevated = 
            factor(findInterval(m_3_4, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(m_3_4>2)%>%
                      pull(m_3_4)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         m_5_12_elevated = "normal", #m_5_12 has no values above 2, so we just hack the error of trying to find the median of a NULL vector. They are all normal.
         ifn_1_el_sherb_elevated = 
            factor(findInterval(ifn_1_el_sherb, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(ifn_1_el_sherb>2)%>%
                      pull(ifn_1_el_sherb)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         ifn_2_el_sherb_elevated = 
            factor(findInterval(ifn_2_el_sherb, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(ifn_2_el_sherb>2)%>%
                      pull(ifn_2_el_sherb)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         ifn_2_siddiqi_elevated = 
            factor(findInterval(ifn_2_siddiqi, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(ifn_2_siddiqi>2)%>%
                      pull(ifn_2_siddiqi)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         tnf_elevated = 
            factor(findInterval(tnf_related, 
           c(-Inf, 2, table1.cytokine_scores %>% 
                      filter( timepoint =="baseline") %>% 
                      filter(tnf_related>2)%>%
                      pull(tnf_related)%>%
                      median(), 
             Inf)),
           labels=c("normal","Slightly Elevated","Highly Elevated")),
         il6_elevated = "normal", #il-6 related Z-scores are also not above 2.
         .keep = "none"
         )



table1.cytokine_scores_combined <- table1.cytokine_scores %>% left_join(table1.IFN.Quant.At.Baseline)

table1.vo2max <- vo2max.data%>% dplyr::select(
  id, mITT, timepoint, treatment, sex,
  kondital, vo_2_max,
  borg_skala_efter_test, hrmax, watt_max
)%>%mutate(
  timepoint = factor(to_snake_case(as.character(timepoint)))
)

table1.SLEDAI.data <- SLEDAI.data %>% dplyr::select(
  id, timepoint,
  SLEDAI_score, vas_sledai_physician, SRI_50_score
)%>%mutate(
  timepoint = factor(to_snake_case(as.character(timepoint)))
)

table1.SLICC.data <- SLICC.data %>% dplyr::select(
  id, slicc_score) %>% mutate(timepoint = "baseline")

table1.kidney <- Bloodsamples %>%
  filter(timepoint == "baseline" | timepoint == "followup")%>%
  filter(order_within_day == "1")%>%
  dplyr::select(id, timepoint, `Kreatinin;P`, `eGFR / 1,73mÂ² (CKD-EPI)`)%>%
  mutate(creatinine = `Kreatinin;P`,
         eGFR = `eGFR / 1,73mÂ² (CKD-EPI)`,
         .keep = "unused")%>%dplyr::left_join(
          Bloodsamples.data%>%dplyr::select(
            id, 
            timepoint, 
            urin_leukocytter,
            urin_protein,
            urin_blod), 
          by=c("id","timepoint")
         )

table1.dexa<- `_c_visit__anthropometrics_and_dxa.mITT.data` %>% 
  dplyr::select(id, sex, task_name, dato_dxa, 
                total_fat, total_fat_001, 
                android_fat_mass_g, android_fat_mass_g_001,
                gynoid_fatt_mass_g, gynoid_fatt_mass_g_001,
                total_muscle_mass_g, bone_mass_density_g_cm_3)%>%mutate(
  timepoint=
  case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline",  
    T~NA_character_
  ), .keep = "unused") %>% relocate(
    id, timepoint, sex, dato_dxa
  )

table1.activity.measures <- 
  AX3_Data.Frame %>% filter(
  location == "back") %>%
  dplyr::select(
                id, timepoint, location, 
                calendar_date, startday,
                dur_spt_min_pla,
                dur_day_total_IN_min_pla, dur_day_total_LIG_min_pla,
                duration_daily_MVPA_pla, dur_day_total_MOD_min_pla,
                dur_day_total_VIG_min_pla)

table1.other.anthropometric <- read_excel(path=here("Data/easy_trial_seperate_schemes",                                                   paste0("anamnese_og_objektiv_undersÃ¸gelse_baseline_followup.",
                                         ifelse(mITT,"mITT",
                                          ifelse(PP, "PP","")),".data .xlsx")))%>%
  mutate(timepoint=case_when(
    task_name == "Visit 5 - Follow-Up" ~ "followup",
    task_name == "Visit 1 - Samtykke, Telefonopkald, Inklusion + Ekslusion" ~ "screening",
     grepl("Baseline",task_name) ~ "baseline"))%>%
  dplyr::select(id, treatment,sex,timepoint, mITT, PP, 
                hÃ¸jde, weight, taljeomkreds, 
                etnisk_oprindelse, etnicitet_anden, 
                systolisk_bt, diastolisk_bt,
                sle_start_dato,tidligere_medicin_sle,
                tidligere_medicin_sle_001,
                hvilket_medicin_anden_relevant,
                hvilket_medicin_anden_relevant_001,
                hvilket_medicin_002,
                rituximab, #TODO add dose, update output from easytrial
                cyklofosfamid, #TODO add dose etc. update easytrial to reflect.
                andet_medicin, hvilket_andet, dosis_andet,
                andet_med_2, hvilket_andet_med_2, andet_med_dosis,
                andet_med_3, hvilket_andet_med_3, dosis_andet_med_3,
                andet_med_4, hvilket_andet_med_4, dosis_andet_med_4
                )%>%mutate(
    AktuelSLEMedicin = tidligere_medicin_sle_001,
    .keep="unused"
  )

```

## Creating table 1 from data sets

```{r}

data.table1 <- table1.vo2max %>% left_join(
  table1.cytokine_scores_combined, by=c("id","timepoint"), keep =F
            )%>% left_join(
  table1.kidney, by=c("id","timepoint")
            )%>% left_join(
  table1.questionnaires, by=c("id","timepoint", "sex"), keep =F
            )%>% left_join(
  table1.SLEDAI.data, by=c("id","timepoint")
            )%>% left_join(
  table1.SLICC.data, by=c("id","timepoint")
            )%>% left_join(
  table1.dexa, by=c("id","timepoint","sex"), keep =F
            )%>%left_join(
  table1.activity.measures, by=c("id","timepoint"), keep =F
            )%>%
  relocate(
  id, timepoint, treatment, sex, kondital, fatigue.mean) %>%
  group_by(id)#TODO create this dataset



```

# Data Wrangling for analysis of all genes

Using suggestions from Kanwal Siddiqi

```{r eval = F}
nanostring_norm

diffex.data<-nanostring_norm %>%  dplyr::select(!c("Class Name", 
                   "Probe Name",
                    BX0616_014, 
                    BX0616_103,  
                    BX0616_110))%>%as.data.frame()

rownames(diffex.data) <- nanostring_norm$`Probe Name`



PVals_ExFUvsNoExFu <- apply(nanostring_norm[-1],1,function(x) t.test(x[exercisers],x[nonexercisers]))
```

## Using RNASEQ2 package.

--- I can't get the below code to work. I think I will try making my own above and not evaluating this. #TODO

https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#standard-workflow

Love, M.I., Huber, W., Anders, S. (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.Â *Genome Biology*,Â **15**:550.Â [10.1186/s13059-014-0550-8](http://dx.doi.org/10.1186/s13059-014-0550-8)

https://www.biorxiv.org/content/10.1101/2020.04.08.032490v3.full.pdf

```{r warning=F}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
#install.packages("fastmap", force = T)
library(fastmap)

#BiocManager::install("rnaseqGene")
#browseVignettes("rnaseqGene")
library(rnaseqGene)
#library(tximeta)



```

## Create data sets

```{r}


column.data.to.remove1 <- nanostring_biox %>% 
  dplyr::rename(id=ID)%>%
  dplyr::select(c(BX_ID, timepoint, id)) %>%
  mutate(id = to_snake_case(id))%>%
  left_join(group, by = join_by(id))%>%
  filter(timepoint=="Extra")

column.data.to.remove2 <- nanostring_biox %>% 
  dplyr::rename(id=ID)%>%
  dplyr::select(c(BX_ID, timepoint, id)) %>%
  mutate(id = to_snake_case(id))%>%
  left_join(group, by = join_by(id))%>%
  filter(is.na(treatment))

count.data <- nanostring %>% 
  dplyr::select(!c("Class Name", 
                   "Probe Name",
                    BX0616_014, 
                    BX0616_103,  
                    BX0616_110,
                   column.data.to.remove1$BX_ID,
                   column.data.to.remove2$BX_ID)
                )%>%as.data.frame()

rownames(count.data)<-nanostring$`Probe Name`

head(count.data)
#str(count.data)
count.data<-as.data.frame(lapply(count.data,as.numeric))
#str(count.data)


column.data <- nanostring_biox %>% 
  dplyr::rename(id=ID)%>%
  dplyr::select(c(BX_ID, timepoint, id)) %>%
  mutate(id = to_snake_case(id))%>%
  left_join(group, by = join_by(id))%>%
  filter(!is.na(treatment) )%>%
  filter(timepoint!="Extra")


all(colnames(count.data) == column.data$BX_ID)



library("DESeq2")
dds <- DESeqDataSetFromMatrix(countData = count.data,
                              colData = column.data,
                              design = ~ timepoint + timepoint:treatment)
dds
dds <- DESeq(dds)
res <- results(dds)
res

summary(res)
#View(res)

plotMA(res, ylim=c(-2,2))
```

## Using DEseq for the volcanoplots

```{r}



#dds <- DESeqDataSetFromMatrix(countData = nanostringforvolcano,
 #                             colData = column.data,
  #                            design= ~ batch + condition)
#dds <- DESeq(dds)
#resultsNames(dds) # lists the coefficients
#res <- results(dds, name="condition_trt_vs_untrt")
# or to shrink log fold changes association with condition:
#res <- lfcShrink(dds, coef="condition_trt_vs_untrt", type="apeglm")
```

## Using the Limma Package

As the DEseq2 doesn't account for mixed effect models, staying more true to our original design would be having a random effect of id. This is also a boon because I have problems getting the DEseq2 to compile correctly.

We are using this guide: https://www.bioconductor.org/packages/devel/workflows/vignettes/RNAseq123/inst/doc/limmaWorkflow.html

We should remember to cite this: Ritchie, ME, Phipson, B, Wu, D, Hu, Y, Law, CW, Shi, W, and Smyth, GK (2015). limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic Acids Research 43(7), e47

Also we could use this as a guideline:

<https://www.researchgate.net/publication/377981363_Impact_of_modeled_microgravity_stress_on_innate_immunity_in_a_beneficial_animal-microbe_symbiosis>

```{r limma dependencies, warning = F}
#BiocManager::install("Glimma")
#BiocManager::install("Mus.musculus")
library(limma)
library(Glimma)
library(edgeR)
library(Mus.musculus)
renv::update()
```

So we should build the data from the count matrix

```{r}
count.data 


all(colnames(count.data) == column.data$BX_ID)

column.data2 <- column.data %>% mutate(
  treat = case_when(
    timepoint == "Baseline" ~ "None",
    treatment == "SÃ¸lÃ¸ve" ~ "SÃ¸lÃ¸ve",
    treatment == "Pingvin" ~ "Pingvin",
    T ~ "None"
  )
    ,
  farve = case_when(
    treat== "SÃ¸lÃ¸ve" ~ "Blue",
    treat == "Pingvin" ~ "Red",
    treat == "None" ~ "Black",
    T~ "Black"
  )
)


#get sex to id,
sex.id <- rawdata %>% as.data.frame()%>%mutate(id=to_snake_case(allocation_no))%>% dplyr::select(id, sex) 
sex.id <- sex.id[!duplicated(sex.id$id),]

column.data2<- left_join(column.data2, sex.id)



DGE.count.data <- DGEList(counts = count.data, group = column.data2$treatment)
DGE.count.data$samples$timepoint <- column.data2$timepoint
DGE.count.data$samples$id <- column.data2$id
DGE.count.data$samples$sex <- column.data2$sex
DGE.count.data$samples$treat <- column.data2$treat
DGE.count.data$samples$treatment <- column.data2$treatment

all(colnames(DGE.count.data) == column.data2$BX_ID)

plotMDS(DGE.count.data, labels = column.data2$id, plot=T, col = (column.data2$farve))

norm.factor.count.data <- calcNormFactors(DGE.count.data)
DGE.count.data <- calcNormFactors(DGE.count.data)

#keep.exprs <- filterByExpr(DGE.count.data, design=design)
#x <- DGE.count.data[keep.exprs,, keep.lib.sizes=FALSE]
#dim(x)

```

### LIMMA Specify the model

```{r evaluate = F}

norm.factor.count.data <- calcNormFactors(DGE.count.data, method ="TMM")
all(colnames(norm.factor.count.data) == column.data$BX_ID)

norm.factor.count.data$samples$norm.factors
#TODO continue down this rabbit hole 
design <- model.matrix(~0+timepoint+treatment+treatment*timepoint+sex,data=DGE.count.data$samples)
colnames(design) <- gsub("group", "", colnames(design))
design


v<- voom(DGE.count.data, design = design, block=DGE.count.data$samples$id,plot = T)
v
#contr.matrix <- makeContrasts(
 #  "Ex Vs No Ex" = treatmentSÃ¸lÃ¸ve, 
  # "Followup vs Baseline" = timepointFollowup - timepointBaseline, 
   #levels = colnames(design))
#contr.matrix
#getEAWP(v)
#install.packages("statmod")
library(statmod)
#duplicateCorrelation(object = v, design)
library(limma)
library(edgeR)
dupC <- limma::duplicateCorrelation(object = v, design = design, block = v$targets$id)

vfit <- lmFit(v, correlation = dupC, design = design)
efit <- eBayes(vfit)
plotSA(efit, main="Final model: Mean-variance trend")

cnf.DGE.count.data <- calcNormFactors(DGE.count.data)
fit <- voomLmFit(cnf.DGE.count.data, design = design, plot=TRUE)
fit <- eBayes(fit)

volcanoplot(fit)
```
